{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime,time\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.svm import SVC\n",
        "import math\n",
        "import statistics\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "# 4 ML models without Cross-Validation\n",
        "df=pd.read_csv('\/data\/workspace_files\/train.csv')\n",
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# pipe for each model\n",
        "pipe1 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier()),])\n",
        "\n",
        "pipe2 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier(loss='log')),])\n",
        "\n",
        "pipe3 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier(loss='modified_huber')),])\n",
        "\n",
        "pipe4 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier(loss='perceptron')),])\n",
        "\n",
        "\n",
        "# list of thr models as pipes\n",
        "list_of_models = {'SGD Classifier with Hinge Loss':pipe1,\n",
        "                  'SGD Classifier with Log Loss':pipe2, \n",
        "                  'SGD Classifier with Modified Huber Loss':pipe3, \n",
        "                  'SGD Classifier with perceptron Loss':pipe4}\n",
        "\n",
        "\n",
        "def get_Model_results(models,X_train,y_train,X_test,y_test):\n",
        "  \n",
        "    for model_name, model in list_of_models.items():\n",
        "        \n",
        "        start_time =  time.time()%60\n",
        "        text_clf = model.fit(X_train, y_train)\n",
        "        end_time= time.time()%60\n",
        "        \n",
        "        if(end_time>start_time):\n",
        "            time_to_build_the_model='%.2f' %(end_time-start_time)\n",
        "        else:\n",
        "            time_to_build_the_model='%.2f' %(start_time-end_time)\n",
        "                \n",
        "        \n",
        "        start_time = time.time()%60\n",
        "        predicted = text_clf.predict(X_test)\n",
        "        end_time= time.time()%60\n",
        "        \n",
        "        if(end_time>start_time):\n",
        "            time_to_predict='%.2f' %(end_time-start_time)\n",
        "        else:\n",
        "            time_to_predict='%.2f' %(start_time-end_time)\n",
        "                \n",
        "        \n",
        "        print('\\n................................................\\nModel {}'.format(model_name))\n",
        "        print(confusion_matrix(y_test,predicted))\n",
        "        print(classification_report(y_test,predicted))\n",
        "        print('\\nAccuracy on Training:\\n{00:.2f}'.format(text_clf.score(X_train,y_train)*100))\n",
        "    \n",
        "        print('\\nAccuracy on Testing:\\n{00:.2f}'.format(accuracy_score(y_test,predicted)*100))\n",
        "       \n",
        "        print('\\nTime taken to build the model is {} Seconds'.format(time_to_build_the_model))\n",
        "        print('\\nTime taken for prediction is {} Seconds'.format(time_to_predict))\n",
        "\n",
        "\n",
        "\n",
        "get_Model_results(list_of_models,X_train,y_train,X_test,y_test)\n"
      ],
      "execution_count":0,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "\n",
            "................................................\n",
            "Model SGD Classifier with Hinge Loss\n",
            "[[1103  215]\n",
            " [ 256  710]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.82      1318\n",
            "           1       0.77      0.73      0.75       966\n",
            "\n",
            "    accuracy                           0.79      2284\n",
            "   macro avg       0.79      0.79      0.79      2284\n",
            "weighted avg       0.79      0.79      0.79      2284\n",
            "\n",
            "\n",
            "Accuracy on Training:\n",
            "97.02\n",
            "\n",
            "Accuracy on Testing:\n",
            "79.38\n",
            "\n",
            "Time taken to build the model is 0.29 Seconds\n",
            "\n",
            "Time taken for prediction is 0.10 Seconds\n",
            "\n",
            "................................................\n",
            "Model SGD Classifier with Log Loss\n",
            "[[1140  178]\n",
            " [ 259  707]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84      1318\n",
            "           1       0.80      0.73      0.76       966\n",
            "\n",
            "    accuracy                           0.81      2284\n",
            "   macro avg       0.81      0.80      0.80      2284\n",
            "weighted avg       0.81      0.81      0.81      2284\n",
            "\n",
            "\n",
            "Accuracy on Training:\n",
            "92.44\n",
            "\n",
            "Accuracy on Testing:\n",
            "80.87\n",
            "\n",
            "Time taken to build the model is 0.23 Seconds\n",
            "\n",
            "Time taken for prediction is 0.09 Seconds\n",
            "\n",
            "................................................\n",
            "Model SGD Classifier with Modified Huber Loss\n",
            "[[1076  242]\n",
            " [ 253  713]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.81      1318\n",
            "           1       0.75      0.74      0.74       966\n",
            "\n",
            "    accuracy                           0.78      2284\n",
            "   macro avg       0.78      0.78      0.78      2284\n",
            "weighted avg       0.78      0.78      0.78      2284\n",
            "\n",
            "\n",
            "Accuracy on Training:\n",
            "99.51\n",
            "\n",
            "Accuracy on Testing:\n",
            "78.33\n",
            "\n",
            "Time taken to build the model is 0.20 Seconds\n",
            "\n",
            "Time taken for prediction is 0.09 Seconds\n",
            "\n",
            "................................................\n",
            "Model SGD Classifier with perceptron Loss\n",
            "[[1000  318]\n",
            " [ 239  727]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.76      0.78      1318\n",
            "           1       0.70      0.75      0.72       966\n",
            "\n",
            "    accuracy                           0.76      2284\n",
            "   macro avg       0.75      0.76      0.75      2284\n",
            "weighted avg       0.76      0.76      0.76      2284\n",
            "\n",
            "\n",
            "Accuracy on Training:\n",
            "99.16\n",
            "\n",
            "Accuracy on Testing:\n",
            "75.61\n",
            "\n",
            "Time taken to build the model is 0.20 Seconds\n",
            "\n",
            "Time taken for prediction is 0.09 Seconds\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "from collections import defaultdict\n",
        "# Same 4 models, but with 10-Fold Cross Validation including building and testing time of the model \n",
        "\n",
        "df=pd.read_csv('\/data\/workspace_files\/train.csv')\n",
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "\n",
        "# pipe for each model\n",
        "pipe1 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier()),])\n",
        "\n",
        "pipe2 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier(loss='log')),])\n",
        "\n",
        "pipe3 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier(loss='modified_huber')),])\n",
        "\n",
        "pipe4 = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "                     ('clf', SGDClassifier(loss='perceptron')),])\n",
        "\n",
        "\n",
        "# list of thr models as pipes\n",
        "list_of_models = {'SGD Classifier with Hinge Loss':pipe1,\n",
        "                  'SGD Classifier with Log Loss':pipe2, \n",
        "                  'SGD Classifier with Modified Huber Loss':pipe3, \n",
        "                  'SGD Classifier with perceptron Loss':pipe4}\n",
        "\n",
        "models_accuracy = defaultdict()\n",
        "models_built_time=defaultdict()\n",
        "models_prediction_time=defaultdict()\n",
        "\n",
        "\n",
        "\n",
        "def CV_model_score(models,X,y):\n",
        "    kf = KFold(n_splits=10,random_state=42,shuffle=True)\n",
        "    for model_name, model in list_of_models.items():\n",
        "        single_modele_scores=[]\n",
        "        single_modele_build_time=[]\n",
        "        single_modele_predict_time=[]\n",
        "        single_modele_scores_for_training=[]\n",
        "        for train_index, test_index in kf.split(X,y):\n",
        "         \n",
        "            \n",
        "            start_time =  time.time()%60\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "            text_clf = model.fit(X_train, y_train)\n",
        "            end_time= time.time()%60\n",
        "            if(end_time>start_time):\n",
        "                 time_to_build_the_model=float('%.2f' %(end_time-start_time))\n",
        "            else:\n",
        "                time_to_build_the_model=float('%.2f' %(start_time-end_time))\n",
        "            \n",
        "            single_modele_build_time.append(time_to_build_the_model)\n",
        "            start_time = time.time()%60\n",
        "            predicted = text_clf.predict(X_test)\n",
        "            end_time= time.time()%60\n",
        "            if(end_time>start_time):\n",
        "                time_to_predict=float('%.2f' %(end_time-start_time))\n",
        "            else:\n",
        "                time_to_predict=float('%.2f' %(start_time-end_time))\n",
        "            single_modele_predict_time.append(time_to_predict)\n",
        "            \n",
        "            testing_accuracy=float('%.2f' %(accuracy_score(y_test,predicted)*100))\n",
        "            single_modele_scores.append(testing_accuracy)\n",
        "            \n",
        "            training_accuracy=float('%.2f' %(text_clf.score(X_train,y_train)*100))\n",
        "            single_modele_scores_for_training.append(training_accuracy)\n",
        "        \n",
        "        models_accuracy[model_name]=single_modele_scores\n",
        "        testing_accuracy=statistics.mean(single_modele_scores)\n",
        "        training_accuracy=statistics.mean(single_modele_scores_for_training)\n",
        "        models_built_time=statistics.mean(single_modele_build_time)\n",
        "        models_prediction_time=statistics.mean(single_modele_predict_time)\n",
        "        \n",
        "        print('\\n--------------------------------------\\nModel {}'.format(model_name))\n",
        "        print('Accuracy on Training\\n')\n",
        "        print('%.2f' %training_accuracy)\n",
        "        print('\\nAccuracy on Testing\\n')\n",
        "        print('%.2f' %testing_accuracy)\n",
        "        print('\\nTime taken to build the model is {00:.2f} Seconds'.format(models_built_time))\n",
        "        print('\\nTime taken to predict is {00:.2f} Seconds'.format(models_prediction_time))\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "CV_model_score(list_of_models,X,y)"
      ],
      "execution_count":0,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "\n",
            "--------------------------------------\n",
            "Model SGD Classifier with Hinge Loss\n",
            "Accuracy on Training\n",
            "\n",
            "95.40\n",
            "\n",
            "Accuracy on Testing\n",
            "\n",
            "79.90\n",
            "\n",
            "Time taken to build the model is 0.27 Seconds\n",
            "\n",
            "Time taken to predict is 0.03 Seconds\n",
            "\n",
            "--------------------------------------\n",
            "Model SGD Classifier with Log Loss\n",
            "Accuracy on Training\n",
            "\n",
            "90.61\n",
            "\n",
            "Accuracy on Testing\n",
            "\n",
            "80.30\n",
            "\n",
            "Time taken to build the model is 0.27 Seconds\n",
            "\n",
            "Time taken to predict is 0.03 Seconds\n",
            "\n",
            "--------------------------------------\n",
            "Model SGD Classifier with Modified Huber Loss\n",
            "Accuracy on Training\n",
            "\n",
            "99.22\n",
            "\n",
            "Accuracy on Testing\n",
            "\n",
            "78.81\n",
            "\n",
            "Time taken to build the model is 0.26 Seconds\n",
            "\n",
            "Time taken to predict is 0.03 Seconds\n",
            "\n",
            "--------------------------------------\n",
            "Model SGD Classifier with perceptron Loss\n",
            "Accuracy on Training\n",
            "\n",
            "99.08\n",
            "\n",
            "Accuracy on Testing\n",
            "\n",
            "76.14\n",
            "\n",
            "Time taken to build the model is 0.25 Seconds\n",
            "\n",
            "Time taken to predict is 0.03 Seconds\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Method to plot the result\n",
        "\n",
        "def resutls_visulization(list_of_resutls):\n",
        "   \n",
        "    model_names = list(list_of_resutls.keys())\n",
        "    results = [list_of_resutls[model] for model in model_names]\n",
        "    fig = go.Figure()\n",
        "    for model, result in zip(model_names, results):\n",
        "        fig.add_trace(go.Box(\n",
        "            y=result,\n",
        "            name=model,\n",
        "            boxpoints='all',\n",
        "            jitter=0.8,\n",
        "            whiskerwidth=0.9,\n",
        "            marker_size=5,\n",
        "            line_width=2)\n",
        "        )\n",
        "        \n",
        "    \n",
        "    fig.update_layout(\n",
        "    title='Performance of 4 ML Models Using 10-Fold Cross-Validation',\n",
        "    paper_bgcolor='rgb(243, 243, 243)',\n",
        "    plot_bgcolor='rgb(243, 243, 243)',\n",
        "    showlegend=True)\n",
        "    fig.update_yaxes(title_text=\"<b>Accuracy % <\/b>\")\n",
        "    fig.update_xaxes(title_text=\"<b>ML Model<\/b>\")\n",
        "    fig.show()"
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "resutls_visulization(models_accuracy)"
      ],
      "execution_count":0,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}